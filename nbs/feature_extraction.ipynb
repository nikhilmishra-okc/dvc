{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nikhilmishra_okcredit_in/okcredit_github/retraining_pipeline/training_pipeline\n"
     ]
    }
   ],
   "source": [
    "%cd \"~/okcredit_github/retraining_pipeline/training_pipeline\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "from okcredit_ml.ml_pipeline import classifier, model, validation\n",
    "\n",
    "from okcredit_ml.cloud_connectors import gcp\n",
    "from copy import deepcopy\n",
    "from src import utils\n",
    "\n",
    "sys.path.append('../feature_pipeline/')\n",
    "sys.path.append('../feature_pipeline/svc')\n",
    "from OKCFeaturePipeline import OKCFeaturePipeline\n",
    "\n",
    "from pathlib import Path\n",
    "from google.cloud import storage\n",
    "\n",
    "gcp_bq = gcp.BQPy(project_id='okcredit-data-science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = OmegaConf.load('./configs/data_config.yaml')\n",
    "feature_pipe_config = OmegaConf.load(\"./configs/feature_pipeline_config_template.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File test_bnpl.csv downloaded to ./data/test_bnpl.csv\n",
      "File test_tl.csv downloaded to ./data/test_tl.csv\n",
      "File train_bnpl.csv downloaded to ./data/train_bnpl.csv\n",
      "File train_comb.csv downloaded to ./data/train_comb.csv\n",
      "File train_tl.csv downloaded to ./data/train_tl.csv\n"
     ]
    }
   ],
   "source": [
    "utils.download_files_from_gcs_folder(project=data_config.data_path.gcs.project,\n",
    "                                     bucket_name=data_config.data_path.gcs.bucket_name,\n",
    "                                     gcs_folder_path=data_config.data_path.gcs.input_data,\n",
    "                                     local_save_path=data_config.data_path.local)\n",
    "\n",
    "\n",
    "utils.create_folder_in_gcs(\n",
    "    project=data_config.data_path.gcs.project,\n",
    "    bucket_name=data_config.data_path.gcs.bucket_name,\n",
    "    folder_name=data_config.data_path.gcs.features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ./data/train_tl.csv\n",
      "Loaded ./data/train_bnpl.csv\n",
      "Loaded ./data/test_bnpl.csv\n",
      "Loaded ./data/test_tl.csv\n"
     ]
    }
   ],
   "source": [
    "for df_name in data_config.create_features_for_files:\n",
    "    \n",
    "    file_path = os.path.join(data_config.data_path.local, df_name) + '.csv'\n",
    "    df = pd.read_csv(file_path)\n",
    "    print(f'Loaded {file_path}')\n",
    "    \n",
    "    df['run_date'] = pd.to_datetime(df['run_date'])\n",
    "\n",
    "    config = utils.create_config_from_template(feature_pipe_config, df_name)\n",
    "    OmegaConf.save(config=config, f=f'./configs/feature_pipeline_config_{df_name}.yaml')\n",
    "    \n",
    "    gcp_bq.load_pandas_df(df, disposition='WRITE_TRUNCATE', destination=config.basetables.cohort)\n",
    "    print(f'Written {df_name} to {config.basetables.cohort}')\n",
    "\n",
    "    print(f'Starting feature pipeline for {df_name}')\n",
    "    \n",
    "    # Delete the old feature pipeline outptu table if it exists, since feature pipeline always appends to the table\n",
    "    gcp_bq.delete_table(config.sink)\n",
    "    pipeline = OKCFeaturePipeline(config=config)\n",
    "    pipeline.predict(X=['2022-08-13'], names= ['run_date'])\n",
    "\n",
    "    print(f'Completed feature pipeline for {df_name}')\n",
    "    \n",
    "    print(f'Cleaning up temporary tables')\n",
    "    utils.cleanup_tables(project=data_config.data_path.gcs.project, config=config)\n",
    "    \n",
    "    fts_df = gcp_bq.bq_to_pandas(f'SELECT * FROM `{config.sink}`')\n",
    "    fts_df['run_date'] = pd.to_datetime(fts_df['run_date'])\n",
    "    train_df = pd.merge(df, fts_df, on=['merchant_id', 'run_date'], how='left')\n",
    "\n",
    "    save_filename = f'{df_name}_fts.csv'\n",
    "\n",
    "    local_file_path = os.path.join(data_config.data_path.local, save_filename)\n",
    "    train_df.to_csv(local_file_path, index=False)\n",
    "    \n",
    "    utils.copy_from_local_to_gcs(\n",
    "        project=data_config.data_path.gcs.project,\n",
    "        bucket_name=data_config.data_path.gcs.bucket_name,\n",
    "        gcs_file_path=os.path.join(data_config.data_path.gcs.features, save_filename),\n",
    "        local_file_path=local_file_path\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
