{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/nikhilmishra_okcredit_in/okcredit_github/retraining_pipeline/training_pipeline\n"
     ]
    }
   ],
   "source": [
    "%cd \"~/okcredit_github/retraining_pipeline/training_pipeline/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "from omegaconf import OmegaConf\n",
    "from okcredit_ml.ml_pipeline import classifier, model, validation\n",
    "\n",
    "from okcredit_ml.cloud_connectors import gcp\n",
    "from copy import deepcopy\n",
    "\n",
    "\n",
    "sys.path.append('..')\n",
    "from src import utils\n",
    "\n",
    "sys.path.append('../feature_pipeline/')\n",
    "sys.path.append('../feature_pipeline/svc')\n",
    "from OKCFeaturePipeline import OKCFeaturePipeline\n",
    "\n",
    "from pathlib import Path\n",
    "from google.cloud import storage\n",
    "import joblib\n",
    "import gc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "gcp_bq = gcp.BQPy(project_id='okcredit-data-science')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_config = OmegaConf.load('./configs/train_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File test_bnpl_fts.csv downloaded to ./data/test_bnpl_fts.csv\n",
      "File test_tl_fts.csv downloaded to ./data/test_tl_fts.csv\n",
      "File train_bnpl_fts.csv downloaded to ./data/train_bnpl_fts.csv\n",
      "File train_tl_fts.csv downloaded to ./data/train_tl_fts.csv\n",
      "File test_bnpl.csv downloaded to ./data/test_bnpl.csv\n",
      "File test_tl.csv downloaded to ./data/test_tl.csv\n",
      "File train_bnpl.csv downloaded to ./data/train_bnpl.csv\n",
      "File train_comb.csv downloaded to ./data/train_comb.csv\n",
      "File train_tl.csv downloaded to ./data/train_tl.csv\n"
     ]
    }
   ],
   "source": [
    "utils.download_files_from_gcs_folder(project=train_config.input_path.gcs.project,\n",
    "                                     bucket_name=train_config.input_path.gcs.bucket_name,\n",
    "                                     gcs_folder_path=train_config.input_path.gcs.features,\n",
    "                                     local_save_path=train_config.input_path.local.base)\n",
    "\n",
    "utils.download_files_from_gcs_folder(project=train_config.input_path.gcs.project,\n",
    "                                     bucket_name=train_config.input_path.gcs.bucket_name,\n",
    "                                     gcs_folder_path=train_config.input_path.gcs.input_data,\n",
    "                                     local_save_path=train_config.input_path.local.base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = utils.read_multiple_dfs(train_config.input_path.local.base, train_config.input_path.local.train.features)\n",
    "if 'order' in train_config.input_path.local.train:\n",
    "    order_df = utils.read_multiple_dfs(train_config.input_path.local.base, train_config.input_path.local.train.order)\n",
    "    order_df = order_df.drop_duplicates(subset=['merchant_id', 'run_date', 'target'], keep='last').reset_index(drop=True)\n",
    "    train_df = pd.merge(order_df, train_df, on=['merchant_id', 'run_date', 'target'], how='left')\n",
    "    \n",
    "    del order_df\n",
    "    _ = gc.collect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_kwargs = {} if train_config.model.model_kwargs is None else train_config.model.model_kwargs\n",
    "estimator_obj = getattr(model, train_config.model[\"class\"])(**param_kwargs)\n",
    "\n",
    "validation_kwargs = {} if train_config.validation.kwargs is None else train_config.validation.kwargs\n",
    "validation_scheme = getattr(validation, train_config.validation['class'])(**validation_kwargs)\n",
    "\n",
    "classifier_obj = classifier.Classifier(model=estimator_obj,\n",
    "                                       validation=validation_scheme ,\n",
    "                                       modelling_columns=train_config.column_profile.features,\n",
    "                                       categorical_columns=train_config.column_profile.categorical,\n",
    "                                       target='target')\n",
    "\n",
    "classifier_obj.fit(train_df, train_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder gs://okcredit-data-science/okc_underwriting/model_retraining_pipeline/v1_1/artifacts/ already exists in gcs\n",
      "File ./artifacts/model.pkl uploaded to model_retraining_pipeline/v1_1/artifacts/model.pkl\n"
     ]
    }
   ],
   "source": [
    "if train_config.output_path.model.local is not None:\n",
    "    Path(train_config.output_path.model.local).mkdir(parents=True, exist_ok=True)\n",
    "    local_file_path = os.path.join(train_config.output_path.model.local, train_config.output_path.model.save_name)\n",
    "    joblib.dump(classifier_obj, local_file_path)\n",
    "    \n",
    "    if train_config.output_path.model.gcs is not None:\n",
    "        utils.create_folder_in_gcs(\n",
    "            project=train_config.output_path.model.gcs.project,\n",
    "            bucket_name=train_config.output_path.model.gcs.bucket_name,\n",
    "            folder_name=train_config.output_path.model.gcs.folder_name\n",
    "        )\n",
    "\n",
    "        utils.copy_from_local_to_gcs(\n",
    "            project=train_config.output_path.model.gcs.project,\n",
    "            bucket_name=train_config.output_path.model.gcs.bucket_name,\n",
    "            gcs_file_path=os.path.join(train_config.output_path.model.gcs.folder_name, train_config.output_path.model.save_name),\n",
    "            local_file_path=local_file_path\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File ./artifacts/test_scores.csv uploaded to model_retraining_pipeline/v1_1/artifacts/test_scores.csv\n"
     ]
    }
   ],
   "source": [
    "if 'test' in train_config.input_path.local:\n",
    "    \n",
    "    test_df = utils.read_multiple_dfs(train_config.input_path.local.base, train_config.input_path.local.test.features)\n",
    "    test_df['model_preds'] = classifier_obj.predict(test_df)\n",
    "    \n",
    "    scores_df = test_df[['target', 'model_preds', 'file_name']].groupby('file_name').apply(lambda x: roc_auc_score(x['target'], x['model_preds'])).rename('AUC score').reset_index()\n",
    "\n",
    "    output_file_name = 'test_scores.csv' if train_config.output_path.test_scores is None else train_config.output_path.test_scores.save_name\n",
    "\n",
    "    local_file_path = os.path.join(train_config.output_path.model.local, output_file_name)\n",
    "    scores_df.to_csv(local_file_path, index=False)\n",
    "\n",
    "    utils.copy_from_local_to_gcs(\n",
    "        project=train_config.output_path.model.gcs.project,\n",
    "        bucket_name=train_config.output_path.model.gcs.bucket_name,\n",
    "        gcs_file_path=os.path.join(train_config.output_path.model.gcs.folder_name, output_file_name),\n",
    "        local_file_path=local_file_path\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
